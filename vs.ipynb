{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4718786,"sourceType":"datasetVersion","datasetId":2730182}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kerthi99055/safegrid-testcode?scriptVersionId=220811765\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:04:52.717796Z","iopub.execute_input":"2025-02-04T18:04:52.718007Z","iopub.status.idle":"2025-02-04T18:04:56.916675Z","shell.execute_reply.started":"2025-02-04T18:04:52.717987Z","shell.execute_reply":"2025-02-04T18:04:56.915711Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\n\n# Path to the dataset\ndataset_path = \"/kaggle/input/rwf2000/RWF-2000\"\n\n# Function to calculate video duration\ndef get_video_duration(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        return 0\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n    duration = frame_count / fps if fps > 0 else 0\n    cap.release()\n    return duration\n\n# Function to process dataset\ndef process_dataset(dataset_path):\n    folder_stats = {}\n    total_duration = 0\n\n    for root, dirs, files in os.walk(dataset_path):\n        video_count = 0\n        folder_duration = 0\n        for file in files:\n            if file.endswith((\".mp4\", \".avi\", \".mkv\")): \n                video_count += 1\n                video_path = os.path.join(root, file)\n                folder_duration += get_video_duration(video_path)\n        \n        if video_count > 0:\n            folder_name = os.path.basename(root)\n            folder_stats[folder_name] = {\n                \"video_count\": video_count,\n                \"duration\": folder_duration\n            }\n            total_duration += folder_duration\n\n    return folder_stats, total_duration\n\n# Process the dataset\nstats, total_duration = process_dataset(dataset_path)\n\n# Print results\nfor folder, data in stats.items():\n    print(f\"Folder: {folder}\")\n    print(f\"  Videos: {data['video_count']}\")\n    print(f\"  Duration: {data['duration']:.2f} seconds\\n\")\n\nprint(f\"Total Duration of Dataset: {total_duration:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:04:56.917787Z","iopub.execute_input":"2025-02-04T18:04:56.918457Z","iopub.status.idle":"2025-02-04T18:05:11.770816Z","shell.execute_reply.started":"2025-02-04T18:04:56.918418Z","shell.execute_reply":"2025-02-04T18:05:11.769961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import the neccesary libraries \nimport os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:05:11.771694Z","iopub.execute_input":"2025-02-04T18:05:11.77193Z","iopub.status.idle":"2025-02-04T18:05:23.987846Z","shell.execute_reply.started":"2025-02-04T18:05:11.77191Z","shell.execute_reply":"2025-02-04T18:05:23.987044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nIMG_SIZE = 64  # Resize frames to 64x64\nSEQ_LENGTH = 30  # Number of frames per video\nDATASET_PATH = \"/kaggle/input/rwf2000/RWF-2000\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:05:23.990219Z","iopub.execute_input":"2025-02-04T18:05:23.990768Z","iopub.status.idle":"2025-02-04T18:05:23.994845Z","shell.execute_reply.started":"2025-02-04T18:05:23.990741Z","shell.execute_reply":"2025-02-04T18:05:23.993785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preprocess videos\ndef load_preprocess_videos(path, label, limit=None):\n    videos = []\n    labels = []\n    count = 0\n    for video_name in os.listdir(path):\n        video_path = os.path.join(path, video_name)\n        cap = cv2.VideoCapture(video_path)\n        frames = []\n        while len(frames) < SEQ_LENGTH:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n            frame = frame / 255.0  \n            frames.append(frame)\n        cap.release()\n        \n        if len(frames) == SEQ_LENGTH:\n            videos.append(np.array(frames))\n            labels.append(label)\n            count += 1\n            if limit and count >= limit:\n                break\n    return np.array(videos), np.array(labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:09:09.356152Z","iopub.execute_input":"2025-02-04T18:09:09.356501Z","iopub.status.idle":"2025-02-04T18:09:09.362236Z","shell.execute_reply.started":"2025-02-04T18:09:09.356472Z","shell.execute_reply":"2025-02-04T18:09:09.361478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_dataset():\n    X_train, y_train, X_test, y_test = [], [], [], []\n    for label, subfolder in enumerate(['Fight', 'NonFight']):\n        train_path = os.path.join(DATASET_PATH, 'train', subfolder)\n        \n        # Reserve 10% of training videos as test set\n        videos, labels = load_preprocess_videos(train_path, label)\n        split_idx = int(0.1 * len(videos))  # 10% split\n        \n        X_test.extend(videos[:split_idx])\n        y_test.extend(labels[:split_idx])\n        X_train.extend(videos[split_idx:])\n        y_train.extend(labels[split_idx:])\n    \n    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:05:24.020591Z","iopub.execute_input":"2025-02-04T18:05:24.020878Z","iopub.status.idle":"2025-02-04T18:05:24.029688Z","shell.execute_reply.started":"2025-02-04T18:05:24.02085Z","shell.execute_reply":"2025-02-04T18:05:24.028482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model():\n    model = Sequential([\n        Conv3D(32, (3, 3, 3), activation='relu', input_shape=(SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3)),\n        MaxPooling3D((2, 2, 2)),\n        BatchNormalization(),\n        Conv3D(64, (3, 3, 3), activation='relu'),\n        MaxPooling3D((2, 2, 2)),\n        BatchNormalization(),\n        Conv3D(128, (3, 3, 3), activation='relu'),\n        MaxPooling3D((2, 2, 2)),\n        BatchNormalization(),\n        Flatten(),\n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        Dense(2, activation='softmax')  # Two classes: Fight, NonFight\n    ])\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n    \n# Prepare the data\nprint(\"Loading dataset...\")\nX_train, y_train, X_test, y_test = prepare_dataset()\ny_train = to_categorical(y_train, num_classes=2)  # Convert labels to one-hot encoding\ny_test = to_categorical(y_test, num_classes=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:09:22.634858Z","iopub.execute_input":"2025-02-04T18:09:22.63518Z","iopub.status.idle":"2025-02-04T18:10:56.058495Z","shell.execute_reply.started":"2025-02-04T18:09:22.635152Z","shell.execute_reply":"2025-02-04T18:10:56.057738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-validation split from training set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n# Build and train the model\nprint(\"Building model...\")\nmodel = build_model()\n\nprint(\"Training model...\")\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_val, y_val))\n\n# Save the model\nmodel.save('violence_detection_model.h5')\nprint(\"Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:14:08.501776Z","iopub.execute_input":"2025-02-04T18:14:08.502125Z","iopub.status.idle":"2025-02-04T18:15:21.497296Z","shell.execute_reply.started":"2025-02-04T18:14:08.502084Z","shell.execute_reply":"2025-02-04T18:15:21.496498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on test data\nprint(\"Evaluating on test set...\")\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:15:51.09221Z","iopub.execute_input":"2025-02-04T18:15:51.09255Z","iopub.status.idle":"2025-02-04T18:15:52.218061Z","shell.execute_reply.started":"2025-02-04T18:15:51.092523Z","shell.execute_reply":"2025-02-04T18:15:52.216684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef predict_video(frames):\n    frames = np.expand_dims(np.array(frames), axis=0)  \n    prediction = model.predict(frames)\n    classes = ['Fight', 'NonFight']\n    return classes[np.argmax(prediction)]\n\nprint(\"Testing individual test videos...\")\nfor i in range(5):  \n    frames = X_test[i]\n    actual_label = 'Fight' if np.argmax(y_test[i]) == 0 else 'NonFight'\n    predicted_label = predict_video(frames)\n    print(f\"Actual: {actual_label}, Predicted: {predicted_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T18:05:24.452028Z","iopub.status.idle":"2025-02-04T18:05:24.452335Z","shell.execute_reply":"2025-02-04T18:05:24.452212Z"}},"outputs":[],"execution_count":null}]}